{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNliJwCKv+Ct8lhm0zTYzq7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImranNust/AppliedDataScience-CapstonProject/blob/main/Chapter4/Module1_WorkingWithImages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> <center> <b> <u> Important Points </u> </b> </center> </h1>\n",
        "\n",
        "\n",
        "\n",
        "* Scalars representing values at individual pixels are often encoded using 8-bit integers. \n",
        "* In medical, scientific, and industrial applications, it is not unusual to find higher numerical precision, such as 12-bit or 16-bit. This allows a wider range or increased sensitivity in cases where the pixel encodes information about a physical property, like bone density, temperature, or depth.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "V5dgPwJrM661"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> <center> <b> <u> Loading an Image </u> </b> </center> </h2>"
      ],
      "metadata": {
        "id": "kb2bg5eIN4Ff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TN-K_XbM3fA",
        "outputId": "b46ff259-adb2-423e-da8f-d0beda34e634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Images folder already exists; therefore, reading the image directly\n",
            "Image Size: (720, 1280, 3)\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "try:\n",
        "  print(\"[INFO] Images folder already exists; therefore, reading the image directly\")\n",
        "  img_file = 'Images/bobby.jpg'\n",
        "  img_arr = imageio.imread(img_file)\n",
        "except:\n",
        "  print(\"[INFO] Images folder does not exist; therefore, dowonloading it.. cheers...\")\n",
        "  !git clone https://github.com/ImranNust/DeepLearningWithPyTorch\n",
        "  !mv DeepLearningWithPyTorch/Images .\n",
        "  !rm -rf DeepLearningWithPyTorch\n",
        "  img_file = 'Images/bobby.jpg'\n",
        "  img_arr = imageio.imread(img_file)\n",
        "\n",
        "\n",
        "print('Image Size: {}'.format(img_arr.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<h2> <center> <b> <u> Changing the Layout </u> </b> </center> </h2>\n",
        "\n",
        "img is a NumPy array-like object with three dimensions: $H\\times W\\times C$. \n",
        "PyTorch modules dealing with image data require tensors to be laid out as $C\\times H\\times W$. We will, therefore, use the `permute' function to make the dimensions PyTorch Compatible.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "S1L5ATv1cxaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# coverting numpy to pytorch tensors\n",
        "img = torch.from_numpy(img_arr) \n",
        "\n",
        "# permuting to bring the channels to the first position\n",
        "out = img.permute(2, 0, 1)\n",
        "\n",
        "print('Now the size is {}'.format(out.shape))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LZ5setdOw4o",
        "outputId": "62dc7c60-2c38-41a2-8de5-11364bb40fb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now the size is torch.Size([3, 720, 1280])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "[IMPORTANT]: note that this operation does not make a copy of the tensor data. Instead, `out` uses the same underlying storage as `img` and only plays with The size and stride information at the tensor level. This is convenient because the operation is very cheap; but just as a heads-up: **changing a pixel in img will lead to a change in out.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PTx9wWImemLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Let's build a tensor, using `stack`, where we can pre-allocate a tensor of appropriate size and fill it with images loaded from a directory.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AA3miXedfI0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "batch_size = 3\n",
        "batch = torch.zeros(batch_size, 3, 256, 256, dtype = torch.uint8)\n",
        "\n",
        "\"\"\"\n",
        "This indicates that our batch will consist of three RGB images 256 pixels in \n",
        "height and 256 pixels in width.\n",
        "\"\"\"\n",
        "\n",
        "# We can now load all PNG images from an input directory and store them in the \n",
        "# tensor\n",
        "data_dir = 'Images/image-cats/'\n",
        "filenames = [name for name in os.listdir(data_dir)\n",
        "if os.path.splitext(name)[-1] == '.png']\n",
        "\n",
        "for i, filename  in enumerate(filenames):\n",
        "  img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
        "  img_t = torch.from_numpy(img_arr)\n",
        "  img_t = img_t.permute(2, 0, 1)\n",
        "  img_t = img_t[:3]\n",
        "  batch[i] = img_t"
      ],
      "metadata": {
        "id": "BmrZfHtURyB8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<h2> <center> <b> <u> Normalizing the Data </u> </b> </center> </h2>\n",
        "\n",
        "* Neural networks exhibit the best training performance when the input data ranges roughly from 0 to 1, or from -1 to 1. \n",
        "\n",
        "* So a typical thing weâ€™ll want to do is cast a tensor to floating-point and normalize the values of the pixels. Casting to floating-point is easy, but normalization is trickier, as it depends on what range of the input we decide should lie between 0 and 1 (or -1 and 1). One possibility is to just divide the values of the pixels by 255 (the maximum representable number in 8-bit unsigned):\n",
        "\n",
        "```\n",
        "batch = batch.float()\n",
        "batch /= 255.0\n",
        "```\n",
        "\n",
        "Another possibility is to compute the mean and standard deviation of the input data and scale it so that the output has zero mean and unit standard deviation across each channel:\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "t5ficagLjEOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = batch.float()\n",
        "batch /= 255.0\n",
        "n_channels = batch.shape[1]\n",
        "for c in range(n_channels):\n",
        "  mean = torch.mean(batch[:, c])\n",
        "  std = torch.std(batch[:, c])\n",
        "  batch[:, c] = (batch[:, c] - mean) / std"
      ],
      "metadata": {
        "id": "SQHOzpXXiUdW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "[IMPORTANT]: NOTE Here, we normalize just a single batch of images because we do not know yet how to operate on an entire dataset. In working with images, it is good practice to compute the mean and standard deviation on all the training data in advance and then subtract and divide by these fixed, precomputed quantities.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0ftAkmLckpk0"
      }
    }
  ]
}