{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImranNust/AppliedDataScience-CapstonProject/blob/main/00_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ff998b5-4d1e-4b95-993c-a656d429dd9f",
      "metadata": {
        "id": "2ff998b5-4d1e-4b95-993c-a656d429dd9f"
      },
      "source": [
        "# Atrium Segmentation\n",
        "\n",
        "In this lecture series, we will build a neural network which will automatically segment the left atrium in cardiac MRI images as usual.\n",
        "\n",
        "- Segmenting and image is the process of assigning a specific class to all pixels or voxels in an image. In our case, this means that each voxel is either classified as 'not left atrium' or 'left atrium'.\n",
        "\n",
        "- This segmentation of the atrium allows to exactly calculate its volume. Changes in atrial volume are associated with multiple cardiac disorders, such as atrial fibrillation or mitral valve stenosis, which basically is a narrowing of the mitral valve orifice blocking blood flow to the heart chambers. However, as you might already imagine, Manuel's, like, is an extremely tedious task because the radiologist has to manually recommend the left atrium in all slices where it is visible.\n",
        "\n",
        "- Therefore, let's automates it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d83da61-f201-43f4-ba9d-80d65820702f",
      "metadata": {
        "id": "2d83da61-f201-43f4-ba9d-80d65820702f"
      },
      "source": [
        "---\n",
        "\n",
        "## Data\n",
        "\n",
        "We can use the cardiac MRI dataset provided by the medical segmentation they and the medical segmentation decathlon, or in short, MSD is a challenge consisting of 10 different medical segmentation tasks. Atrium segmentation is one of them.\n",
        "\n",
        "- The corresponding dataset consists of 20 MRI scans of the heart with corresponding ground truth masks in the two dimensional setting.\n",
        "\n",
        "- It's up to 4542 2D slices. \n",
        "\n",
        "\n",
        "\n",
        "- You can download and preprocess the data for the segmentation task for cardiac mri images:\n",
        "  - The data is provided by the medical segmentation decathlon (http://medicaldecathlon.com/)\n",
        "  - (Data License: https://creativecommons.org/licenses/by-sa/4.0/)\n",
        "\n",
        "- You can directly download the cardiac MRIs and segmentation maps from:\n",
        "https://drive.google.com/file/d/1wEB2I6S6tQBVEPxir8cA5kFB8gTQadYY/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f9e860-e128-4752-b428-cb22378d1b99",
      "metadata": {
        "id": "09f9e860-e128-4752-b428-cb22378d1b99"
      },
      "source": [
        "---\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "\n",
        "In general, there are two ways we could tackle this problem.\n",
        "\n",
        "1. The first possibility is to work in the three dimensional setting by using 3D convolutions. However, using three dimensional convolutions is extremely memory hungry and computational expensive. Therefore, let's work in a two dimensional setting by extracting the single slices.\n",
        "\n",
        "2. Our original image shape is 252 squared. However, as we are only interested in the cardiac regions, we could crop away the noncardiac regions and the background by removing the first 32 rows or columns from all borders. Please note that you'll also have to crop the segmentation masks next.\n",
        "\n",
        "    - We prefer a z-normalization on the subject level. This means that we compute mean and standard deviation for each subject separately before said, normalizing the corresponding skin.\n",
        "\n",
        "    - Subsequently, we standardize the normalized subject into the $[0, 1]$ range by performing minimax scaling to evaluate the China realization ability of our model.\n",
        "    \n",
        "    $$ X_s = \\frac{X_n - min(X_n)}{max(X_n) - min(X_n)} $$\n",
        "\n",
        "\n",
        "- We only use 16 patients as training data and the remaining four for validation purposes.\n",
        "\n",
        "- After pre-processing our data, it's time to talk about the dataset.\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c782c7d-c223-4017-ad5b-c369f95f8471",
      "metadata": {
        "id": "5c782c7d-c223-4017-ad5b-c369f95f8471"
      },
      "source": [
        "---\n",
        "\n",
        "## Datasets\n",
        "\n",
        "1. At first, our dataset needs to create a list of all two dimensional slices.\n",
        "\n",
        "2. Next, given an index, it has to load displays and corresponding label mask.\n",
        "\n",
        "3. After loading our data, We have to augment slice and mask identically.\n",
        "\n",
        "4. Last but not least, we need to return the augmented slice and mask.\n",
        "\n",
        "**Data Augmentation**\n",
        "\n",
        "- we use scaling,  rotation and elastic transformations for augmentation.\n",
        "\n",
        "- Elastic transformations augment an image by moving the pixels locally around using a displacement field.\n",
        "\n",
        "Before talking about the training routine, let's discuss the model we will manually implement."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42aab2a4-217b-43f1-9958-3762232ce03c",
      "metadata": {
        "id": "42aab2a4-217b-43f1-9958-3762232ce03c"
      },
      "source": [
        "---\n",
        "## Model\n",
        "\n",
        "\n",
        "- One of the most famous segmentation models in this lecture called UNet.\n",
        "\n",
        "- The UNet was proposed by Raymond Berger at All Atomic Height 2015.\n",
        "\n",
        "- It consists of an encoder decoder architecture with skip connections.\n",
        "\n",
        "- The encoder has the task of reducing the feature Maps by using normal convolutions and max pooling layers.\n",
        "\n",
        "- In contrast, the decoder has to reconstruct the segmentation mask based on the original image and the features by using upsampling, layers and also normal convolutions.\n",
        "\n",
        "- Last but not least, the use of Skip connections allows an information flow directly from the encoder to the decoder.\n",
        "\n",
        "- This drastically reduces the problem of vanishing gradients.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7870c321-204a-4943-8cf2-43795a8f2c55",
      "metadata": {
        "id": "7870c321-204a-4943-8cf2-43795a8f2c55"
      },
      "source": [
        "---\n",
        "\n",
        "## Training\n",
        "\n",
        "\n",
        "- We will train our model by using the Adam optimizer with an initial learning rate of 0.0001.\n",
        "\n",
        "- Together with the currently most used loss for segmentation loss called dice loss, the dice loss is\n",
        "\n",
        "$$L(\\hat{y}, y) = 1 - \\frac{2|\\hat{y} \\cap y|}{|\\hat{y}|+|\\hat{y}|}$$\n",
        "\n",
        "- In code, as we are working in the binary setting, we can simply compute the intersection in the counter by calculating the sum of the element twice product between prediction and label. The denominator is simply calculated by adding the sum of the predictions to the sum of the masks. Additionally, as both the prediction and mask might be zero, we add a really small number to the denominator\n",
        "```\n",
        "counter = (pred * mask).sum() # Numerator\n",
        "denum = pred.sum() + mask.sum() + 1e-8 # Denominator\n",
        "dice = 1 - (2*counter)/denum\n",
        "```\n",
        "\n",
        "- Threshold at 0.5\n",
        "    - Predictions > 0.5  -> Atrium\n",
        "    - Predictions <= 0.5 -> Not Atrium\n",
        "\n",
        "\n",
        "\n",
        "- we train our model for 75 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a66706-0796-41c0-804d-8263a42f2994",
      "metadata": {
        "id": "18a66706-0796-41c0-804d-8263a42f2994"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyTorchForMedicalEnv",
      "language": "python",
      "name": "pytorchformedical"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}